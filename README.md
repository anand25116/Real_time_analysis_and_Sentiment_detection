# ğŸ›’ Real-Time Analysis & Sentiment Detection of Amazon Electronics Reviews

**Authors:**

* **Anand Nareshkumar Patel**, Department of Computer Science, Rutgers University â€” *[ap3085@scarletmail.rutgers.edu](mailto:ap3085@scarletmail.rutgers.edu)*
* **Anish Vishnu Shirodkar**, Department of Computer Science, Rutgers University â€” *[sa2792@scarletmail.rutgers.edu](mailto:sa2792@scarletmail.rutgers.edu)*
* **Santanu Agarwal**, Department of Computer Science, Rutgers University â€” *[avs181@scarletmail.rutgers.edu](mailto:avs181@scarletmail.rutgers.edu)*

ğŸ“„ **Paper (NeurIPS-style write-up):** *Included in repository*
ğŸ¥ **Video Demo:** [https://drive.google.com/drive/folders/1pZVumiUZ8kDg64_L9Nos3egtc8w0X0O4](https://drive.google.com/drive/folders/1pZVumiUZ8kDg64_L9Nos3egtc8w0X0O4)
ğŸ’» **Code Repository:** [https://github.com/anand25116/Real_time_analysis_and_Sentiment_detection](https://github.com/anand25116/Real_time_analysis_and_Sentiment_detection)

---

## ğŸ“Œ Overview

This project implements an **end-to-end sentiment classification pipeline** on large-scale
**Amazon Electronics reviews**, using:

### ğŸ”¹ Baseline Model

* **TF-IDF + Logistic Regression**

### ğŸ”¹ Transformer Models

* **DistilBERT**
* **RoBERTa**

We compare:

* Prediction accuracy
* Computational efficiency
* Contextual understanding
* Interpretability trade-offs

In addition, we extract **topics from positive vs negative reviews** and build a **Streamlit real-time review simulator** that streams reviews, visualizes model predictions, and shows product information.

---

## ğŸ¯ Motivation

* Amazon review volume makes **manual trend analysis impossible**
* Sellers need **fast detection of dissatisfaction spikes**
* Users care about aspects like **battery life, durability, and performance**
* Transformers capture **context, negation, sarcasm**, unlike Bag-of-Words

Our model:

* Classifies reviews into **negative (0), neutral (1), positive (2)**
* Shows major **product aspect mentions**
* Streams **live review sentiment**

---

## ğŸ“‚ Dataset Summary

### ğŸŸ¦ Source

* **Amazon Reviews 2023 â€” McAuley-Lab (Electronics subset)**
* ~100,000 reviews sampled using chunk-loading for memory efficiency

Each record includes:

* review text
* star rating (1â€“5)
* timestamp
* product identifier

### ğŸŸ© Sentiment Mapping

| Star Rating | Sentiment    |
| ----------- | ------------ |
| â­ 1â€“2       | Negative (0) |
| â­ 3         | Neutral (1)  |
| â­ 4â€“5       | Positive (2) |

### ğŸŸ¨ Supplementary Dataset (for Streamlit UI)

* **Kaggle Amazon Sales**
* Images, product names, pricing

Not used in training â€” used for **visual context**.

---

## ğŸ§¹ Data Cleaning Pipeline

* Load via chunked `pandas.read_json(..., chunksize=50000)`
* Lower-casing
* Strip HTML tags
* Remove URLs
* Keep only alphabetic content
* Filter short reviews
* Convert UNIX timestamps
* Compute review length feature
* Save **electronics_reviews_clean.csv**

---

## ğŸ§ª Baseline Model: TF-IDF + Logistic Regression

* `TfidfVectorizer(max_features=20000, ngram_range=(1,2))`
* Stratified train-test split (80/20)
* `LogisticRegression(max_iter=1000, solver="lbfgs")`

Artifacts saved:

```
models/tfidf.pkl
models/logreg.pkl
models/baseline_config.pkl
```

---

## ğŸ¤– Transformer Training

Both models fine-tuned using Hugging Face `Trainer`.

### ğŸŸ¦ DistilBERT

* `distilbert-base-uncased`
* `num_labels=3`
* Batch-size=16
* Epochs=2
* `max_length=256`

Saved to:

```
models/bert_sentiment/
```

### ğŸŸ© RoBERTa

* `roberta-base`
* Batch-size=8
* Epochs=2

Saved to:

```
models/roberta_sentiment/
```

---

## ğŸ“Š Model Performance

A bar chart compares:

* Logistic Regression
* DistilBERT
* RoBERTa

Transformers outperform baseline in accuracy and contextual handling â€” consistent with literature.

---

## ğŸ” Aspect-Level Insights

Using spaCy noun phrase extraction:

* Extract most common nouns in top 500 positive reviews
* Extract most common nouns in top 500 negative reviews

Provides **business intelligence** (battery, sound, cable, warranty, etc.).

---

## ğŸ“ˆ Visualizations

* Sentiment class distribution
* Model accuracy bars
* Top aspects word frequency
* Real-time streaming UI

---

## ğŸ–¥ï¸ Streamlit Real-Time Sentiment Simulator

Features:

* Upload CSV
* Product search (e.g., â€œiPhone 15â€)
* Display product image
* Stream N reviews with configurable interval
* Predictions from:

  * BERT pipeline
  * RoBERTa pipeline
  * TF-IDF Logistic baseline

Color-coded:

* ğŸŸ¢ Positive
* ğŸŸ¡ Neutral
* ğŸ”´ Negative

---

## ğŸ—ï¸ System Architecture

```
Data Collection â†’ Cleaning â†’ Labeling â†’ Train Test Split
     â†“
Baseline Model (TF-IDF + LR)
     â†“
Transformer Fine-Tuning (DistilBERT & RoBERTa)
     â†“
Evaluation â†’ Aspect Extraction â†’ Real-Time Web App
```

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/anand25116/Real_time_analysis_and_Sentiment_detection
cd Real_time_analysis_and_Sentiment_detection
pip install -r requirements.txt
```

Run Streamlit app:

```bash
streamlit run app.py
```

---

## ğŸ“ Repository Structure

```
data/
    Electronics.jsonl
    electronics_reviews_clean.csv
models/
    tfidf.pkl
    logreg.pkl
    bert_sentiment/
    roberta_sentiment/
notebooks/
streamlit_app/
results/
```

---

## ğŸ§¬ Key Findings

* Logistic Regression is efficient but shallow
* Transformers excel when subtle context matters
* RoBERTa > DistilBERT > Logistic Regression
* Topic extraction adds **explainability**

---

## ğŸ§­ Applications

| Domain           | Benefit                               |
| ---------------- | ------------------------------------- |
| E-commerce       | Detect failing products early         |
| Marketing        | Track user response live              |
| Customer Support | Prioritize negative surge             |
| Research         | Classical vs Transformer benchmarking |

---

## ğŸš€ Future Enhancements

* Sliding window anomaly detection
* Time-series sentiment drift
* Prompt-based LLM evaluation
* Multi-aspect sentiment tagging
* Deploy app on Hugging Face Spaces
* Kafka streaming integration

---

## ğŸ“ License

MIT â€” open for academic + commercial experimentation.

---

## â­ Support

If this work helped you:
**give the repo a star â­** â€” it motivates more research and open-source releases.

---
